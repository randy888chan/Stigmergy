# =========================================================================
# üöÄ Stigmergy - Core Configuration
# =========================================================================
# Copy this file to .env and fill in your details.
#
# --- QUICK START ---
# 1. Choose your primary AI provider (e.g., 'google' or 'openrouter').
# 2. Add the corresponding API key below.
#
# For more advanced setups, see the provider-specific sections.
# -------------------------------------------------------------------------

# =========================================================================
# üß† PRIMARY AI PROVIDER SELECTION
# =========================================================================
# Select the default providers for the main agent tiers.
# Options: 'google', 'openrouter', 'deepseek', 'mistral', 'anthropic', 'openai'
#
# NOTE: The models listed here are suggestions. You can use any compatible
# model from your chosen provider. See stigmergy.config.js for details.

REASONING_PROVIDER=google
REASONING_MODEL=gemini-2.0-flash-thinking-exp

STRATEGIC_PROVIDER=google
STRATEGIC_MODEL=gemini-1.5-pro

EXECUTION_PROVIDER=google
EXECUTION_MODEL=gemini-1.5-flash

UTILITY_PROVIDER=google
UTILITY_MODEL=gemini-1.5-flash-8b

# =========================================================================
# üîë API KEYS - ESSENTIAL
# =========================================================================
# Add the keys for the providers you selected above.

# --- Google Gemini ---
# The default recommended provider for general use.
GOOGLE_API_KEY=your_google_api_key_here

# --- OpenRouter ---
# Access a wide variety of models through a single API.
# Recommended if you want to experiment with models not listed below.
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1


# =========================================================================
# üîß ADVANCED / ALTERNATIVE PROVIDERS
# =========================================================================
# For specialized use cases or if you prefer a different provider.
# To use these, you must update the PROVIDER settings at the top.

# --- OpenAI (GPT Models) ---
# OPENAI_API_KEY=your_openai_api_key_here

# --- Anthropic (Claude Models) ---
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# ANTHROPIC_BASE_URL=https://api.anthropic.com

# --- DeepSeek (Cost-Effective Models) ---
# DEEPSEEK_API_KEY=your_deepseek_api_key_here
# DEEPSEEK_BASE_URL=https://api.deepseek.com

# --- Mistral (European Multilingual Models) ---
# MISTRAL_API_KEY=your_mistral_api_key_here
# MISTRAL_BASE_URL=https://api.mistral.ai/v1

# --- Codestral by Mistral (specialized for code tasks) ---
# CODESTRAL_API_KEY=your_codestral_api_key_here
# CODESTRAL_BASE_URL=https://codestral.mistral.ai/v1

# --- Kimi/Moonshot (Long Context Chinese Models) ---
# KIMI_API_KEY=your_kimi_api_key_here
# KIMI_BASE_URL=https://api.moonshot.ai/v1

# --- Groq (Ultra-Fast Inference) ---
# GROQ_API_KEY=your_groq_api_key_here
# GROQ_BASE_URL=https://api.groq.com/openai/v1

# --- Together AI (Fast Inference) ---
# TOGETHER_API_KEY=your_together_api_key_here
# TOGETHER_BASE_URL=https://api.together.ai/v1


# =========================================================================
# üõ†Ô∏è SYSTEM & INFRASTRUCTURE
# =========================================================================

# --- Neo4j Database ---
# Required for graph-based memory and code intelligence.
# Options: 'required', 'auto', 'memory' (see stigmergy.config.js)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password

# --- System Environment ---
NODE_ENV=development
STIGMERGY_CORE_PATH=.stigmergy-core

# =========================================================================
# üîå OPTIONAL INTEGRATIONS & FEATURES
# =========================================================================

# --- Firecrawl for Web Research ---
FIRECRAWL_API_KEY=your_firecrawl_api_key_here

# --- GitHub Integration ---
# GITHUB_TOKEN=your_github_token_here

# --- Qwen Code Integration ---
# QWEN_API_KEY=your_qwen_api_key_here
# QWEN_BASE_URL=https://api.qwen.com/v1

# --- Lightweight Archon (Supabase) ---
# For alternative storage backend.
# SUPABASE_URL=your_supabase_url
# SUPABASE_ANON_KEY=your_supabase_anon_key

# =========================================================================
# ‚öôÔ∏è ADVANCED MODEL & EXECUTION CONTROLS
# =========================================================================
# These are for fine-tuning performance and cost.

# --- OpenRouter Model Overrides ---
# Use specific models from OpenRouter without changing the global provider.
# OPENROUTER_REASONING_MODEL=deepseek/deepseek-chat
# OPENROUTER_EXECUTION_MODEL=anthropic/claude-3.5-sonnet

# --- Cost Optimization ---
ENABLE_COST_OPTIMIZATION=false
PREFER_CHEAPER_MODELS=false
MAX_COST_PER_REQUEST=0.10

# --- Performance Monitoring ---
ENABLE_PERFORMANCE_MONITORING=true
MIN_SUCCESS_RATE=0.85
MAX_ERROR_RATE=0.15

# --- Execution Strategy ---
# Enable or disable different code execution agents.
ENABLE_INTERNAL_DEV=true
ENABLE_GEMINI_CLI=false
ENABLE_QWEN_CLI=false