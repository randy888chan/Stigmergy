# --- AI Provider Configuration ---
# The system now uses a flexible provider. Set the API key for the service you want to use.
# OpenRouter is recommended for access to a wide variety of models.
OPENROUTER_API_KEY=
LITELLM_MODEL_ID=google/gemini-pro-1.5 # The default model to use with OpenRouter

# --- OR, use a direct provider (the system will prioritize whatever key it finds) ---
# ANTHROPIC_API_KEY=
# OPENAI_KEY=
# FIREWORKS_KEY=

# --- OR, use a custom OpenAI-compatible endpoint (e.g., a local LLM server via LM Studio or Ollama) ---
# OPENAI_ENDPOINT="http://localhost:11434/v1"
# CUSTOM_MODEL="llama3" # The model name your local server is serving

# --- Research Tool Configuration ---
# Firecrawl is now the standard tool for all research (search and scraping).
FIRECRAWL_KEY=

# --- Neo4j Database Configuration (for Code Intelligence) ---
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_database_password

# --- Engine Configuration ---
PORT=3000
