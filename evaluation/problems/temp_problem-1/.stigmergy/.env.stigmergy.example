# Stigmergy Configuration Template
# Copy this file to .env and fill in your API keys
#
# ðŸŽ¯ QUICK SETUP:
# 1. For Google Gemini: Set GOOGLE_API_KEY (recommended for beginners)
# 2. For OpenRouter: Set OPENROUTER_API_KEY + OPENROUTER_BASE_URL (access to many models)
# 3. For specific providers: Uncomment and set keys for DeepSeek, Kimi, Mistral, etc.
#
# ðŸ’¡ PROVIDER RECOMMENDATIONS:
# - Google Gemini: Best overall performance, good pricing
# - OpenRouter: Access to many providers through one API
# - DeepSeek: Most cost-effective, good for Chinese content
# - Kimi: Best for long documents (32K+ context)
# - Mistral: Good for multilingual tasks, EU-based
# - OpenAI: Latest reasoning models (o1-preview)
# - Anthropic: Safest for sensitive content

# === CHOOSE YOUR AI PROVIDERS ===
# Reasoning Models (for planning, analysis, complex tasks)
REASONING_PROVIDER=google    # Options: 'google' or 'openrouter'
REASONING_MODEL=gemini-2.0-flash-thinking-exp  # or 'deepseek/deepseek-chat' for OpenRouter

# Strategic Models (for business planning, architecture)
STRATEGIC_PROVIDER=google    # Options: 'google' or 'openrouter'  
STRATEGIC_MODEL=gemini-1.5-pro  # or 'anthropic/claude-3.5-sonnet' for OpenRouter

# Execution Models (for code implementation, documentation)
EXECUTION_PROVIDER=google    # Options: 'google' or 'openrouter'
EXECUTION_MODEL=gemini-1.5-flash  # or 'anthropic/claude-3.5-sonnet' for OpenRouter

# Utility Models (for simple tasks, validation)
UTILITY_PROVIDER=google      # Options: 'google' or 'openrouter'
UTILITY_MODEL=gemini-1.5-flash-8b  # or 'deepseek/deepseek-chat' for OpenRouter

# === AI PROVIDER API KEYS ===
# Google AI (Gemini) - Required if any provider is set to 'google'
GOOGLE_API_KEY=your_google_api_key_here

# OpenRouter - Required if any provider is set to 'openrouter'
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# OpenRouter Model Overrides (optional)
# OPENROUTER_REASONING_MODEL=deepseek/deepseek-chat
# OPENROUTER_EXECUTION_MODEL=anthropic/claude-3.5-sonnet

# === SYSTEM OPTIMIZATION ===
# Cost Optimization
ENABLE_COST_OPTIMIZATION=false
PREFER_CHEAPER_MODELS=false
MAX_COST_PER_REQUEST=0.10

# Performance Monitoring
ENABLE_PERFORMANCE_MONITORING=true
MIN_SUCCESS_RATE=0.85
MAX_ERROR_RATE=0.15

# Execution Options
ENABLE_INTERNAL_DEV=true
ENABLE_GEMINI_CLI=false
ENABLE_QWEN_CLI=false

# === INFRASTRUCTURE ===
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password

# === OPTIONAL INTEGRATIONS ===
# Research Tools
FIRECRAWL_API_KEY=your_firecrawl_api_key_here

# Alternative AI Providers (for fallback/specialized use)
# OpenAI (latest reasoning models like o1-preview)
# OPENAI_API_KEY=your_openai_api_key_here

# Anthropic Claude (safety-focused reasoning)
# ANTHROPIC_API_KEY=your_anthropic_api_key_here 
# ANTHROPIC_BASE_URL=https://api.anthropic.com

# DeepSeek (cost-effective Chinese provider)
# DEEPSEEK_API_KEY=your_deepseek_api_key_here
# DEEPSEEK_BASE_URL=https://api.deepseek.com
# DEEPSEEK_REASONING_MODEL=deepseek-reasoner
# DEEPSEEK_EXECUTION_MODEL=deepseek-chat

# Kimi/Moonshot (long context Chinese provider) 
# KIMI_API_KEY=your_kimi_api_key_here
# KIMI_BASE_URL=https://api.moonshot.cn/v1
# KIMI_REASONING_MODEL=moonshot-v1-32k

# Mistral (European multilingual provider)
# MISTRAL_API_KEY=your_mistral_api_key_here
# MISTRAL_BASE_URL=https://api.mistral.ai/v1
# MISTRAL_REASONING_MODEL=mistral-large-latest

# Together AI (fast inference provider)
# TOGETHER_API_KEY=your_together_api_key_here
# TOGETHER_BASE_URL=https://api.together.ai/v1

# Groq (ultra-fast inference)
# GROQ_API_KEY=your_groq_api_key_here
# GROQ_BASE_URL=https://api.groq.com/openai/v1

# Additional Storage (for Lightweight Archon)
# SUPABASE_URL=your_supabase_url
# SUPABASE_ANON_KEY=your_supabase_anon_key

# Qwen Code Integration
# QWEN_API_KEY=your_qwen_api_key_here
# QWEN_BASE_URL=https://api.qwen.com/v1

# GitHub Integration
# GITHUB_TOKEN=your_github_token_here

# === SYSTEM CONFIGURATION ===
STIGMERGY_CORE_PATH=.stigmergy-core
NODE_ENV=development