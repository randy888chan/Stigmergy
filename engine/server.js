import '../utils/env_loader.js';  // Load environment with inheritance
import express from "express";
import http from "http";
import { WebSocketServer } from "ws";
import chalk from "chalk";
import { fileURLToPath } from 'url';
import path from 'path';

// Define __dirname for ESM compatibility using function to avoid circular dependency issues
const getDirName = (url) => path.dirname(fileURLToPath(url));
const __dirname = getDirName(import.meta.url);

import * as stateManagerModule from "./state_manager.js";
import stateManager from "../src/infrastructure/state/GraphStateManager.js";
import { createExecutor } from "./tool_executor.js";
import { CodeIntelligenceService } from '../services/code_intelligence_service.js';
import { healthCheck as archonHealthCheck } from '../tools/archon_tool.js';
import { exec } from 'child_process';
import { promisify } from 'util';
import fs from 'fs-extra';
import { generateText, generateObject } from 'ai';
import { z } from 'zod';
import { getModelForTier } from '../ai/providers.js';
import config from "../stigmergy.config.js";
import dashboardRouter from "./dashboard.js";
import yaml from 'js-yaml';
import trajectoryRecorder from "../services/trajectory_recorder.js";
import { getCostTracking } from "./llm_adapter.js"; // Import cost tracking function

const execPromise = promisify(exec);

const stigmergyToolCallSchema = z.object({
  tool: z.string().describe("The name of the tool to call, e.g., 'stigmergy.task'"),
  args: z.record(z.string(), z.any()).describe("The arguments for the tool, as a key-value object with string keys."),
});

// Add the structured communication schema validation

// Define the structured communication schema
const structuredCommunicationSchema = z.object({
  status: z.enum(["success", "failure", "in_progress", "request_clarification"]).optional(),
  type: z.enum(["task_completion", "information_report", "error_report", "clarification_request"]).optional(),
  payload: z.record(z.string(), z.any()).optional()
}).optional();

// Retry utility for handling rate limits and transient errors
async function retryWithBackoff(fn, retries = 3, delay = 1000, backoffFactor = 2) {
  let lastError;
  
  for (let attempt = 1; attempt <= retries; attempt++) {
    try {
      return await fn();
    } catch (error) {
      lastError = error;
      
      // If it's a rate limit error, we should retry
      const isRateLimitError = error.message.toLowerCase().includes('rate limit') ||
                              error.message.includes('429') ||
                              error.message.toLowerCase().includes('quota') ||
                              error.message.toLowerCase().includes('exceeded');
      
      // If it's not a rate limit error or we've exhausted retries, throw the error
      if (!isRateLimitError || attempt === retries) {
        throw error;
      }
      
      const currentDelay = delay * Math.pow(backoffFactor, attempt - 1);
      console.log(chalk.yellow(`[Engine] Rate limit or transient error detected. Retrying in ${currentDelay}ms... (Attempt ${attempt}/${retries})`));
      
      // Wait before retrying
      await new Promise(resolve => setTimeout(resolve, currentDelay));
    }
  }
  
  throw lastError;
}

async function geminiHealthCheck() {
    try {
        await execPromise('gemini --version');
        return { status: 'ok', message: 'Gemini CLI is installed and accessible.' };
    } catch (error) {
        return {
            status: 'error',
            message: 'Gemini CLI not found. The @gemini-executor agent will fail. Please ensure `gemini` is installed (`npm install -g @google/gemini-cli`) and that your system PATH includes the global npm binaries directory.'
        };
    }
}

const SELF_IMPROVEMENT_CYCLE = 10;

export class Engine {
  constructor({ isPowerMode = false } = {}) {
    this.app = express();
    this.server = http.createServer(this.app);
    this.wss = new WebSocketServer({ server: this.server });
    
    this.isPowerMode = isPowerMode;
    this.stateManager = stateManager;
    this.stateManagerModule = stateManagerModule;
    this.codeIntelligence = new CodeIntelligenceService();
    this.executeTool = createExecutor(this);

    this.mainLoopInterval = null;
    this.taskCounter = 0;
    
    this.setupMiddleware();
    this.setupRoutes();
  }

  setupMiddleware() {
    this.app.use(express.json());
    this.app.use((req, res, next) => {
      res.setHeader(
        'Content-Security-Policy',
        "default-src 'self'; img-src 'self' data:; script-src 'self' 'unsafe-inline' 'unsafe-eval'; style-src 'self' 'unsafe-inline'; connect-src 'self' ws:;"
      );
      next();
    });
  }

  setupRoutes() {
    this.app.use('/', dashboardRouter);
    this.app.get('/api/cost', (req, res) => {
      try {
        const costData = getCostTracking();
        res.json(costData);
      } catch (error) {
        console.error(chalk.red(`[API Error] ${error.message}`));
        res.status(500).json({ error: error.message });
      }
    });
    this.app.post('/api/chat', async (req, res) => {
        try {
            const { agentId, prompt } = req.body;
            console.log(chalk.green(`[API] Received request for @${agentId}: "${prompt}"`));
            const agent = this.getAgent(agentId);
            const result = await this.triggerAgent(agent, prompt);
            
            // Handle error responses properly
            if (result.error) {
                res.status(500).json({ error: result.error, toolCall: result.toolCall });
            } else {
                res.json({ response: result });
            }
        } catch (error) {
            console.error(chalk.red(`[API Error] ${error.message}`));
            res.status(500).json({ error: error.message });
        }
    });
  }

  async initialize() {
    console.log(chalk.blue("Initializing Stigmergy Engine and Auditing Connections..."));

    // Check environment variables first
    const requiredEnvVars = this.getRequiredEnvVars();
    const missingVars = requiredEnvVars.filter(varName => !process.env[varName]);
    
    if (missingVars.length > 0) {
        console.error(chalk.red(`[âœ–] Missing required environment variables: ${missingVars.join(', ')}`));
        console.error(chalk.yellow("Please copy .env.example to .env and configure your API keys."));
        return false;
    }

    const archon = await archonHealthCheck();
    if (archon.status === 'ok') {
        console.log(chalk.green(`[âœ”] Archon Power Mode: ${archon.message}`));
    } else {
        console.log(chalk.yellow(`[!] Archon Power Mode: ${archon.message} (Will use standard research tools).`));
    }

    // Test Neo4j connection
    const neo4j = await this.stateManager.testConnection();
    if (neo4j.status === 'ok') {
        console.log(chalk.green(`[âœ”] Neo4j: ${neo4j.message}`));
    } else {
        console.log(chalk.red(`[âœ–] Neo4j: ${neo4j.message}`));
        if (config.features.neo4j === 'required') {
            console.error(chalk.red("Neo4j is required but not available. Please check your configuration."));
            return false;
        }
        console.log(chalk.yellow("Continuing with in-memory state management."));
    }

    const gemini = await geminiHealthCheck();
    if (gemini.status === 'ok') {
        console.log(chalk.green(`[âœ”] Gemini CLI: ${gemini.message}`));
    } else {
        console.log(chalk.yellow(`[!] Gemini CLI: ${gemini.message}`));
    }

    return true;
  }

  getRequiredEnvVars() {
    // Only require variables for the core functional tiers
    const coreProviders = new Set();
    
    // Check which providers are actually used by core tiers
    const coreTiers = ['reasoning_tier', 'strategic_tier', 'execution_tier', 'utility_tier', 's_tier', 'a_tier', 'b_tier'];
    
    coreTiers.forEach(tierName => {
        const tier = config.model_tiers[tierName];
        if (tier && tier.api_key_env) {
            const apiKey = typeof tier.api_key_env === 'function' ? tier.api_key_env() : tier.api_key_env;
            coreProviders.add(apiKey);
        }
    });
    
    const requiredVars = Array.from(coreProviders);
    
    // Add Neo4j if required
    if (config.features.neo4j === 'required') {
        requiredVars.push('NEO4J_URI', 'NEO4J_USER', 'NEO4J_PASSWORD');
    }
    
    return requiredVars;
  }

  async runMainLoop() {
    try {
      const state = await this.stateManager.getState();
      const dispatcher = this.getAgent('dispatcher');

      if (!state.project_status || ['PAUSED', 'EXECUTION_COMPLETE', 'HUMAN_INPUT_NEEDED', 'NEEDS_INITIALIZATION'].includes(state.project_status)) {
        return;
      }

      const allTasks = state.project_manifest?.tasks || [];
      const pendingTasks = allTasks.filter(t => t.status === 'PENDING');
      const completedTasks = allTasks.filter(t => t.status === 'COMPLETED');

      const prompt = `
        System State:
        - Project Status: ${state.project_status}
        - All Tasks: ${allTasks.length}
        - Pending Tasks (${pendingTasks.length}): ${pendingTasks.map(t => t.description).join('; ') || 'None'}
        - Completed Tasks (${completedTasks.length}): ${completedTasks.map(t => t.description).join('; ') || 'None'}

        Instructions:
        Based on the current system state and your core protocols, determine the single next action to take by calling the appropriate tool.
      `;

      // Provide context to the dispatcher
      const context = {
        project_name: state.project_name,
        project_status: state.project_status,
        total_tasks: allTasks.length,
        pending_tasks_count: pendingTasks.length,
        completed_tasks_count: completedTasks.length,
        system_time: new Date().toISOString()
      };

      try {
        const { toolCall } = await this.triggerAgent(dispatcher, prompt, context);

        if (toolCall && toolCall.tool && toolCall.args) {
          console.log(chalk.magenta(`[Dispatcher] Decided to call tool: ${toolCall.tool} with args:`, toolCall.args));
          await this.executeTool(toolCall.tool, toolCall.args, 'dispatcher');
        } else {
          console.error(chalk.red("[Dispatcher] Did not return a valid tool call."), toolCall);
          // Add a state update to prevent getting stuck in a loop on failure
          await this.stateManagerModule.updateStatus({ newStatus: "HUMAN_INPUT_NEEDED", message: "Dispatcher failed to produce a valid tool call." });
        }
      } catch (error) {
        console.error(chalk.red("[Engine] Error during main loop dispatcher cycle:"), error);
         await this.stateManagerModule.updateStatus({ newStatus: "HUMAN_INPUT_NEEDED", message: `Dispatcher cycle failed: ${error.message}` });
      }
    } catch (error) {
      console.error(chalk.red("[Engine] Error getting state in main loop:"), error);
      // Continue running even if there's an error getting the state
    }
  }

  async start() {
    // Standardized port management with intelligent defaults
    let PORT = process.env.PORT || process.env.STIGMERGY_PORT || 3010;
    
    // If port 3010 is not available (e.g., already running from Stigmergy repo), use 3011
    if (process.cwd() !== path.resolve(__dirname, '..') && !process.env.PORT && !process.env.STIGMERGY_PORT) {
      PORT = 3011;
      console.log(chalk.blue(`[Engine] Using port ${PORT} for project directory instance`));
    }
    
    this.server.listen(PORT, () => {
        console.log(chalk.green(`ðŸš€ Stigmergy Engine API server is running on http://localhost:${PORT}`));
        console.log(chalk.blue(`   Watching project at: ${process.cwd()}`));
        console.log(chalk.yellow("   This is a headless engine. Interact with it via your IDE."));
    });
    
    // Store the port for other components to use
    process.env.STIGMERGY_PORT = PORT;
    
    // Set up WebSocket connection handler
    this.wss.on('connection', (ws) => {
      console.log(chalk.blue('[WebSocket] Client connected'));
      
      // Send initial state to the newly connected client
      this.sendStateToClient(ws);
      
      ws.on('close', () => {
        console.log(chalk.blue('[WebSocket] Client disconnected'));
      });
    });
    
    // Subscribe to state changes and broadcast to all connected clients
    this.stateManager.on("stateChanged", (newState) => {
      this.broadcastStateUpdate(newState);
    });
    
    // Increase interval to a more realistic value to avoid spamming the LLM
    this.mainLoopInterval = setInterval(() => this.runMainLoop(), 5000);
  }

  // Send current state to a specific WebSocket client
  async sendStateToClient(ws) {
    try {
      const state = await this.stateManager.getState();
      const performance = await AgentPerformance.getPerformanceInsights();
      const stateWithPerformance = { ...state, performance };
      
      if (ws.readyState === ws.OPEN) {
        ws.send(JSON.stringify(stateWithPerformance));
      }
    } catch (error) {
      console.error(chalk.red('[WebSocket] Error sending state to client:', error));
    }
  }

  // Broadcast state updates to all connected WebSocket clients
  broadcastStateUpdate(newState) {
    const performance = AgentPerformance.getPerformanceInsights();
    const stateWithPerformance = { ...newState, performance };
    
    this.wss.clients.forEach((client) => {
      if (client.readyState === client.OPEN) {
        client.send(JSON.stringify(stateWithPerformance));
      }
    });
  }

  getAgent(agentId) {
    const localOverridePath = path.join(process.cwd(), '.stigmergy', 'agents', `${agentId}.md`);

    let agentPath;

    // 1. Check for a local override
    if (fs.existsSync(localOverridePath)) {
      agentPath = localOverridePath;
      console.log(chalk.blue(`[Engine] Using local override for agent @${agentId} from: ${agentPath}`));
    } else {
      // 2. Fallback to the globally installed (packaged) path
      // The path is relative to this file (engine/server.js) -> ../.stigmergy-core/agents/
      const globalPath = path.resolve(__dirname, '..', '.stigmergy-core', 'agents', `${agentId}.md`);
      
      if (fs.existsSync(globalPath)) {
        agentPath = globalPath;
        console.log(chalk.blue(`[Engine] Using global package agent @${agentId} from: ${agentPath}`));
      } else {
        throw new Error(`Agent definition file not found for: @${agentId}. Searched for local override and in global package.`);
      }
    }

    const content = fs.readFileSync(agentPath, 'utf8');
    const yamlMatch = content.match(/```yaml\s*([\s\S]*?)```/);
    if (!yamlMatch) {
      throw new Error(`Could not find YAML block in agent definition for: ${agentId}`);
    }

    try {
      const agentData = yaml.load(yamlMatch[1]);
      const name = agentData.agent?.name;
      const persona = agentData.agent?.persona;
      const protocols = agentData.agent?.core_protocols;

      if (!name || !persona || !protocols) {
        throw new Error(`Agent ${agentId} is missing name, persona, or core_protocols.`);
      }

      // Construct a comprehensive system prompt
      const systemPrompt = `
        **Name:** ${name}
        **Identity:** ${persona.identity}
        **Role:** ${persona.role}
        **Style:** ${persona.style}

        **Core Protocols (MUST be followed at all times):**
        ${protocols.join('\n\n')}
      `.trim();

      const modelTier = agentData.agent?.model_tier || 'b_tier';

      return { id: agentId, systemPrompt, modelTier };
    } catch (e) {
      console.error(chalk.red(`Error parsing YAML for agent ${agentId}: ${e.message}`));
      throw new Error(`Failed to parse agent definition for: ${agentId}`);
    }
  }

  async triggerAgent(agent, userPrompt, context = {}) {
    console.log(chalk.cyan(`[Engine] Triggering agent: @${agent.id}`));
    
    // Start trajectory recording for this agent call
    const recordingId = trajectoryRecorder.startRecording(`agent_${agent.id}`, {
      agentId: agent.id,
      userPrompt,
      context
    });
    
    try {
      console.log(chalk.blue(`[Engine] Agent model tier: ${agent.modelTier}`));
      
      const model = getModelForTier(agent.modelTier);
      console.log(chalk.blue(`[Engine] Model resolved successfully`));
      
      // Record the LLM call details
      const llmCallDetails = {
        agentId: agent.id,
        modelTier: agent.modelTier,
        systemPrompt: agent.systemPrompt,
        userPrompt
      };
      
      trajectoryRecorder.logLLMInteraction(recordingId, llmCallDetails);
      
      // Enhance the system prompt with context if available
      let enhancedSystemPrompt = agent.systemPrompt;
      if (context && Object.keys(context).length > 0) {
        enhancedSystemPrompt += `

**Context Information:**
${JSON.stringify(context, null, 2)}

Use this context to inform your response.`;
      }

      // Try structured generation first with retry mechanism
      try {
        const { object } = await retryWithBackoff(async () => {
          return await generateObject({
            model,
            schema: stigmergyToolCallSchema,
            system: enhancedSystemPrompt,
            prompt: userPrompt,
          });
        });
        console.log(chalk.green(`[Engine] Structured generation successful`));
        
        // Record the successful response
        trajectoryRecorder.logEvent(recordingId, 'llm_response', { 
          success: true, 
          responseType: 'structured',
          response: object
        });
        
        return { toolCall: object };
      } catch (structuredError) {
        console.log(chalk.yellow(`[Engine] Structured generation failed for ${agent.modelTier}, falling back to text generation`));
        console.log(chalk.blue(`[Engine] Structured error: ${structuredError.message}`));
        
        // Record the structured generation failure
        trajectoryRecorder.logEvent(recordingId, 'llm_response', { 
          success: false, 
          responseType: 'structured',
          error: structuredError.message
        });
        
        // Fallback to text generation with strict prompt engineering and retry mechanism
        const { text } = await retryWithBackoff(async () => {
          return await generateText({
            model,
            system: enhancedSystemPrompt + `\n\nIMPORTANT: You MUST respond with only a valid, minified JSON object that conforms to the required schema and nothing else. Do not include any conversational text, explanations, or markdown formatting. Example: {"tool":"log","args":{"message":"Hello"}}`,
            prompt: userPrompt + `\n\nResponse format: JSON object with 'tool' and 'args' fields only. Respond with valid JSON only, no other text. You MUST respond with only a valid, minified JSON object that conforms to the required schema and nothing else.`,
          });
        });
        
        console.log(chalk.blue(`[Engine] Text generation result: ${text.substring(0, 200)}...`));
        
        // Record the text generation response
        trajectoryRecorder.logEvent(recordingId, 'llm_response', { 
          success: true, 
          responseType: 'text',
          response: text.substring(0, 200)
        });
        
        // Try to parse the JSON response with more robust handling
        try {
          // More robust JSON parsing for various response formats
          let parsed;
          
          // First try to find a JSON object in the response using a more comprehensive regex
          // Look for JSON objects with nested braces support
          const jsonRegex = /\{(?:[^{}]|(?:\{[^{}]*\}))*\}/g;
          const jsonMatch = text.match(jsonRegex);
          if (jsonMatch && jsonMatch.length > 0) {
            // Try parsing each match until we find one that works
            for (const match of jsonMatch) {
              try {
                const cleanedMatch = match.trim();
                parsed = JSON.parse(cleanedMatch);
                break;
              } catch (e) {
                // Continue to next match
                continue;
              }
            }
          }
          
          // If no JSON object found in matches, try to parse the whole text
          if (!parsed) {
            const cleanedText = text.trim();
            // Only try to parse as JSON if it looks like JSON
            if (cleanedText.startsWith('{') && cleanedText.endsWith('}')) {
              parsed = JSON.parse(cleanedText);
            }
          }
          
          // Validate that it has the required fields
          if (parsed && typeof parsed === 'object') {
            console.log(chalk.green(`[Engine] Successfully parsed fallback JSON`));
            // Normalize the response format
            if (!parsed.tool && parsed.action) {
              parsed.tool = parsed.action;
              delete parsed.action;
            }
            // If neither tool nor action exists, create a default log tool call
            if (!parsed.tool) {
              parsed.tool = 'log';
            }
            if (!parsed.args) {
              parsed.args = {};
            }
            // If it's a log tool and we have content, make sure it's in the args
            if (parsed.tool === 'log' && !parsed.args.message) {
              parsed.args.message = text.trim();
            }
            
            // Record the parsed response
            trajectoryRecorder.logEvent(recordingId, 'response_parsed', { 
              success: true,
              parsedResponse: parsed
            });
            
            return { toolCall: parsed };
          }
          
          // If we have a response but it's not in the expected format,
          // create a proper tool call structure with the response as a message
          if (text && text.trim().length > 0) {
            console.log(chalk.green(`[Engine] Creating tool call from text response`));
            const toolCallResponse = { 
              toolCall: { 
                tool: 'log', 
                args: { 
                  message: text.trim(),
                  status: "success",
                  progress: "100%",
                  files_modified: [],
                  next_actions: "awaiting_command",
                  suggestions: [
                    "How can I assist you today?",
                    "Try 'health check' for a detailed system status.",
                    "To begin, you can say 'setup neo4j' or 'index github repos'."
                  ]
                } 
              } 
            };
            
            // Record the tool call creation
            trajectoryRecorder.logEvent(recordingId, 'tool_call_created', { 
              success: true,
              toolCall: toolCallResponse.toolCall
            });
            
            return toolCallResponse;
          }
          
          // If we get here, we don't have a valid response, so throw a specific error
          throw new Error('JSON missing required fields (tool/action)');
        } catch (parseError) {
          console.log(chalk.yellow(`[Engine] Could not parse fallback response: ${parseError.message}`));
          console.log(chalk.yellow(`[Engine] Raw response: ${text}`));
          
          // Record the parsing error
          trajectoryRecorder.logEvent(recordingId, 'response_parsed', { 
            success: false,
            error: parseError.message,
            rawResponse: text
          });
          
          // Even if we can't parse JSON, if we have text content, use it
          if (text && text.trim().length > 0) {
            console.log(chalk.green(`[Engine] Using raw text as message content`));
            const toolCallResponse = { 
              toolCall: { 
                tool: 'log', 
                args: { 
                  message: text.trim(),
                  status: "success",
                  progress: "100%",
                  files_modified: [],
                  next_actions: "awaiting_command",
                  suggestions: [
                    "How can I assist you today?",
                    "Try 'health check' for a detailed system status.",
                    "To begin, you can say 'setup neo4j' or 'index github repos'."
                  ]
                } 
              } 
            };
            
            // Record the tool call creation
            trajectoryRecorder.logEvent(recordingId, 'tool_call_created', { 
              success: true,
              toolCall: toolCallResponse.toolCall
            });
            
            return toolCallResponse;
          }
        }
        
        // Ultimate fallback - create a proper tool call structure
        const toolCallResponse = { 
          toolCall: { 
            tool: 'log', 
            args: { 
              message: `Agent @${agent.id} processed request: ${userPrompt.substring(0, 100)}...`,
              status: "success",
              progress: "100%",
              files_modified: [],
              next_actions: "awaiting_command",
              suggestions: [
                "How can I assist you today?",
                "Try 'health check' for a detailed system status.",
                "To begin, you can say 'setup neo4j' or 'index github repos'."
              ]
            } 
          } 
        };
        
        // Record the tool call creation
        trajectoryRecorder.logEvent(recordingId, 'tool_call_created', { 
          success: true,
          toolCall: toolCallResponse.toolCall
        });
        
        return toolCallResponse;
      }
    } catch (error) {
      console.error(chalk.red(`[Engine] Full error details for @${agent.id}:`));
      console.error(chalk.red(`  Error message: ${error.message}`));
      console.error(chalk.red(`  Agent model tier: ${agent.modelTier}`));
      
      // Record the error
      trajectoryRecorder.logEvent(recordingId, 'agent_error', { 
        error: error.message,
        stack: error.stack
      });
      
      // Check if this is the "Invalid JSON response" error we're seeing
      if (error.message.includes("Invalid JSON response")) {
        // This is our internal error, return the fallback response
        const toolCallResponse = { 
          toolCall: { 
            tool: 'log', 
            args: { 
              message: `Agent @${agent.id} processed request: ${userPrompt.substring(0, 100)}...`,
              status: "success",
              progress: "100%",
              files_modified: [],
              next_actions: "awaiting_command",
              suggestions: [
                "How can I assist you today?",
                "Try 'health check' for a detailed system status.",
                "To begin, you can say 'setup neo4j' or 'index github repos'."
              ]
            } 
          } 
        };
        
        // Record the tool call creation
        trajectoryRecorder.logEvent(recordingId, 'tool_call_created', { 
          success: true,
          toolCall: toolCallResponse.toolCall
        });
        
        return toolCallResponse;
      }
      
      if (error.message.includes("API key environment variable")) {
        console.error(chalk.red(`[Engine] Missing API Key for tier ${agent.modelTier}. Please check your .env file.`));
        const toolCallResponse = { toolCall: { tool: 'log', args: { message: `Agent @${agent.id} trigger failed due to missing API key for tier ${agent.modelTier}.` } } };
        
        // Record the tool call creation
        trajectoryRecorder.logEvent(recordingId, 'tool_call_created', { 
          success: true,
          toolCall: toolCallResponse.toolCall
        });
        
        return toolCallResponse;
      }
      
      // Return a structured error to be handled by the main loop
      const errorResponse = { error: error.message, toolCall: { tool: 'log', args: { message: `Error: ${error.message}`, status: "error" } } };
      
      // Record the error response
      trajectoryRecorder.logEvent(recordingId, 'error_response', { 
        error: error.message,
        toolCall: errorResponse.toolCall
      });
      
      return errorResponse;
    } finally {
      // Finalize the recording
      try {
        const finalState = await this.stateManager.getState();
        await trajectoryRecorder.finalizeRecording(recordingId, { finalState });
      } catch (finalizeError) {
        console.error(chalk.red(`[Engine] Error finalizing trajectory recording: ${finalizeError.message}`));
      }
    }
  }

  stop() {
    return new Promise((resolve) => {
      if (this.mainLoopInterval) {
        clearInterval(this.mainLoopInterval);
      }
      this.server.close(() => {
        console.log('Stigmergy Engine server stopped.');
        resolve();
      });
    });
  }
}

if (process.argv[1] === fileURLToPath(import.meta.url)) {
    const engine = new Engine();
    engine.initialize().then(success => {
        if (success) {
            engine.start();
        } else {
            console.error(chalk.red("Engine initialization failed critical checks. Aborting."));
            process.exit(1);
        }
    });
}
