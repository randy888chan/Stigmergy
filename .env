# .env file

# --- OPTION 1: Custom OpenAI-Compatible Endpoint (HIGHEST PRIORITY) ---
# Example for a local LLM server via LM Studio or Ollama
# OPENAI_ENDPOINT="http://localhost:11434/v1"
# CUSTOM_MODEL="llama3" # The model name your local server is serving

# --- OPTION 2: OpenRouter (RECOMMENDED) ---
# OPENROUTER_API_KEY=your_openrouter_key
# LITELLM_MODEL_ID=google/gemini-pro-1.5 # You can change this to any model on OpenRouter

# --- OPTION 3: Direct OpenAI (FALLBACK) ---
# OPENAI_KEY=your_openai_key

# --- The user's selected model ---
AI_MODEL=kimi-k2-0711-preview

# --- Research Tool Configuration ---
# Get a free key at https://firecrawl.dev
FIRECRAWL_KEY=Fc-b9c1c8d2b91c421ba86a85ea6e1a2358

# --- Neo4j Database Configuration ---
NEO4J_URI=bolt://127.0.0.1:7687
NEO4J_USER=neo4j
# IMPORTANT: Please replace "your_database_password" with your actual Neo4j password.
NEO4J_PASSWORD=your_database_password

# --- Engine Configuration ---
PORT=3010
